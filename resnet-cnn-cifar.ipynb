{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ResNet, Regularization and DataAugmentation\n","metadata":{}},{"cell_type":"markdown","source":"These technique we will use \n* Data Normalization\n* Data Augmentation\n* Residual Connections\n* Batch Normalization\n* Learning rate scheduling\n* Weight Decay\n* Gradient Clipping\n* Adam Optimizer","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:41:11.715568Z","iopub.execute_input":"2024-09-14T18:41:11.715971Z","iopub.status.idle":"2024-09-14T18:41:11.721862Z","shell.execute_reply.started":"2024-09-14T18:41:11.715932Z","shell.execute_reply":"2024-09-14T18:41:11.720920Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"markdown","source":"**1.Data Augmentation and Normalaization**","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32, padding = 4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n])\n\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n\nbatch_size = 128\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = 3, pin_memory = True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers = 3, pin_memory = True )","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:41:11.723590Z","iopub.execute_input":"2024-09-14T18:41:11.723973Z","iopub.status.idle":"2024-09-14T18:41:13.331731Z","shell.execute_reply.started":"2024-09-14T18:41:11.723887Z","shell.execute_reply":"2024-09-14T18:41:13.330839Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:41:13.333527Z","iopub.execute_input":"2024-09-14T18:41:13.333997Z","iopub.status.idle":"2024-09-14T18:41:13.339368Z","shell.execute_reply.started":"2024-09-14T18:41:13.333954Z","shell.execute_reply":"2024-09-14T18:41:13.338452Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**2. CNN model with Residual Block and  batch Normalization**","metadata":{}},{"cell_type":"code","source":"class CNNModelwithResidualandBatchnorm(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.convlayer1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 1)\n        self.batchNormLayer1 = nn.BatchNorm2d(32)\n        self.convlayer2 = nn.Conv2d(in_channels = 32,  out_channels = 64, kernel_size = 3, padding = 1)\n        self.batchNormLayer2 = nn.BatchNorm2d(64)\n        self.Maxpoollayer = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        \n        # 1X1 Conv for matching dimenions\n        self.residual_conv = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 1)\n        \n        self.fullyconnectedlayer = nn.Linear(64 * 16 * 16, 128)\n        self.outputlayer = nn.Linear(128, 10)\n        \n        \n    def forward(self, xb):\n        out = F.relu(self.batchNormLayer1(self.convlayer1(xb)))\n        #residual connection\n        residual = self.residual_conv(out)\n        \n        out = F.relu(self.batchNormLayer2(self.convlayer2(out)))\n        \n        out = out + residual # adding residual conncetion\n        \n        out = self.Maxpoollayer(out)\n        out = out.view(out.size(0), -1)\n        \n        out = F.relu(self.fullyconnectedlayer(out))\n        out = self.outputlayer(out)\n        \n        return out\n    # training step for each batch\n    def training_step(self, batch):\n        images, labels = batch\n        images, labels = images.to(device), labels.to(device)\n        # forward passing the images batch\n        out = self.forward(images)\n        # Loss claculation\n        loss = F.cross_entropy(out, labels)\n        # this function torch.max will take out the maximum probability index = label\n        _, pred = torch.max(out, dim =1)\n        \n        acc = torch.tensor(torch.sum(pred == labels).item()/len(pred))\n        return {'loss': loss, 'acc':acc}\n    \n    #function to calculate epoch matrics\n    def training_epoch_end(self , outputs):\n        batch_losses = [x['loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()\n        \n        batch_acc = [x['acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_acc).mean()\n        \n        return {'loss': epoch_loss.item(), 'acc': epoch_acc.item()}\n    \n    # print result after each epoch\n\n    def epoch_end(self, epoch, result):\n        print(f\"Epoch [{epoch}], train_loss: {result['loss']:.4f}, train_acc: {result['acc']:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:41:13.340431Z","iopub.execute_input":"2024-09-14T18:41:13.340699Z","iopub.status.idle":"2024-09-14T18:41:13.356064Z","shell.execute_reply.started":"2024-09-14T18:41:13.340657Z","shell.execute_reply":"2024-09-14T18:41:13.355113Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\nimport time\ndef evaluate(model, data_loader):\n    outputs = []\n    with torch.no_grad():\n        for batch in data_loader:\n            images, labels = batch\n            images, labels = images.to(device), labels.to(device)\n            output = model.training_step((images, labels))\n            outputs.append(output)\n    return model.training_epoch_end(outputs)\n\n\n# training function\ndef fit(epochs, lr, model, train_loader):\n    history = []\n    # adam optimizer with weight dcay\n    optimizer = optim.Adam(model.parameters(), lr, weight_decay = 1e-4)\n    # Learning Rate Scgheduling\n    #schedular = optim.lr_scheduler.StepLR(optimizer, step_size= 10, gamma = 0.1)\n    \n    total_training_time = 0  # Initialize total training time\n    for epoch in range(epochs):\n        start_time = time.time()\n        for batch in train_loader:\n            images, labels = batch\n            images , labels = images.to(device), labels.to(device)\n            \n            loss_dict = model.training_step((images,labels))\n            loss = loss_dict['loss']\n            loss.backward()\n            \n            #Gadient Clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 2.0)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n        #schedular.step()\n        result = evaluate(model, train_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n        end_time = time.time()\n        epoch_time = end_time - start_time\n\n        total_training_time += epoch_time \n    print(f\"\\nTotal training time: {total_training_time:.2f} seconds\")\n        \n    return history","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:41:13.358209Z","iopub.execute_input":"2024-09-14T18:41:13.358524Z","iopub.status.idle":"2024-09-14T18:41:13.370100Z","shell.execute_reply.started":"2024-09-14T18:41:13.358488Z","shell.execute_reply":"2024-09-14T18:41:13.369250Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"model = CNNModelwithResidualandBatchnorm().to(device)\n\nhistory = fit(80, 0.001, model, train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T18:41:13.371058Z","iopub.execute_input":"2024-09-14T18:41:13.371336Z","iopub.status.idle":"2024-09-14T19:08:06.388752Z","shell.execute_reply.started":"2024-09-14T18:41:13.371305Z","shell.execute_reply":"2024-09-14T19:08:06.387588Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"Epoch [0], train_loss: 1.2746, train_acc: 0.5357\nEpoch [1], train_loss: 1.0986, train_acc: 0.6108\nEpoch [2], train_loss: 1.0259, train_acc: 0.6357\nEpoch [3], train_loss: 0.9796, train_acc: 0.6540\nEpoch [4], train_loss: 0.9162, train_acc: 0.6765\nEpoch [5], train_loss: 0.8931, train_acc: 0.6862\nEpoch [6], train_loss: 0.8607, train_acc: 0.6948\nEpoch [7], train_loss: 0.8750, train_acc: 0.6918\nEpoch [8], train_loss: 0.8312, train_acc: 0.7095\nEpoch [9], train_loss: 0.8380, train_acc: 0.7055\nEpoch [10], train_loss: 0.8072, train_acc: 0.7194\nEpoch [11], train_loss: 0.7813, train_acc: 0.7256\nEpoch [12], train_loss: 0.7807, train_acc: 0.7258\nEpoch [13], train_loss: 0.7667, train_acc: 0.7344\nEpoch [14], train_loss: 0.7478, train_acc: 0.7393\nEpoch [15], train_loss: 0.7281, train_acc: 0.7456\nEpoch [16], train_loss: 0.7672, train_acc: 0.7342\nEpoch [17], train_loss: 0.7362, train_acc: 0.7436\nEpoch [18], train_loss: 0.7345, train_acc: 0.7417\nEpoch [19], train_loss: 0.7058, train_acc: 0.7547\nEpoch [20], train_loss: 0.7112, train_acc: 0.7494\nEpoch [21], train_loss: 0.6921, train_acc: 0.7581\nEpoch [22], train_loss: 0.6876, train_acc: 0.7615\nEpoch [23], train_loss: 0.6896, train_acc: 0.7600\nEpoch [24], train_loss: 0.6712, train_acc: 0.7663\nEpoch [25], train_loss: 0.6630, train_acc: 0.7702\nEpoch [26], train_loss: 0.6621, train_acc: 0.7697\nEpoch [27], train_loss: 0.6531, train_acc: 0.7731\nEpoch [28], train_loss: 0.6616, train_acc: 0.7693\nEpoch [29], train_loss: 0.6500, train_acc: 0.7746\nEpoch [30], train_loss: 0.6570, train_acc: 0.7709\nEpoch [31], train_loss: 0.6592, train_acc: 0.7712\nEpoch [32], train_loss: 0.6318, train_acc: 0.7821\nEpoch [33], train_loss: 0.6307, train_acc: 0.7812\nEpoch [34], train_loss: 0.6273, train_acc: 0.7817\nEpoch [35], train_loss: 0.6272, train_acc: 0.7811\nEpoch [36], train_loss: 0.6291, train_acc: 0.7815\nEpoch [37], train_loss: 0.6195, train_acc: 0.7845\nEpoch [38], train_loss: 0.6174, train_acc: 0.7832\nEpoch [39], train_loss: 0.6142, train_acc: 0.7878\nEpoch [40], train_loss: 0.6109, train_acc: 0.7863\nEpoch [41], train_loss: 0.6056, train_acc: 0.7884\nEpoch [42], train_loss: 0.6256, train_acc: 0.7812\nEpoch [43], train_loss: 0.5970, train_acc: 0.7921\nEpoch [44], train_loss: 0.5970, train_acc: 0.7938\nEpoch [45], train_loss: 0.6004, train_acc: 0.7908\nEpoch [46], train_loss: 0.6024, train_acc: 0.7897\nEpoch [47], train_loss: 0.5867, train_acc: 0.7936\nEpoch [48], train_loss: 0.5950, train_acc: 0.7922\nEpoch [49], train_loss: 0.5822, train_acc: 0.7988\nEpoch [50], train_loss: 0.5871, train_acc: 0.7958\nEpoch [51], train_loss: 0.5921, train_acc: 0.7920\nEpoch [52], train_loss: 0.5857, train_acc: 0.7944\nEpoch [53], train_loss: 0.5735, train_acc: 0.7979\nEpoch [54], train_loss: 0.5821, train_acc: 0.7965\nEpoch [55], train_loss: 0.5789, train_acc: 0.7974\nEpoch [56], train_loss: 0.5898, train_acc: 0.7937\nEpoch [57], train_loss: 0.5678, train_acc: 0.8038\nEpoch [58], train_loss: 0.5799, train_acc: 0.7991\nEpoch [59], train_loss: 0.5725, train_acc: 0.8004\nEpoch [60], train_loss: 0.5553, train_acc: 0.8069\nEpoch [61], train_loss: 0.5536, train_acc: 0.8065\nEpoch [62], train_loss: 0.5623, train_acc: 0.8034\nEpoch [63], train_loss: 0.5701, train_acc: 0.8022\nEpoch [64], train_loss: 0.5607, train_acc: 0.8040\nEpoch [65], train_loss: 0.5534, train_acc: 0.8067\nEpoch [66], train_loss: 0.5502, train_acc: 0.8089\nEpoch [67], train_loss: 0.5591, train_acc: 0.8067\nEpoch [68], train_loss: 0.5489, train_acc: 0.8094\nEpoch [69], train_loss: 0.5388, train_acc: 0.8125\nEpoch [70], train_loss: 0.5349, train_acc: 0.8148\nEpoch [71], train_loss: 0.5357, train_acc: 0.8143\nEpoch [72], train_loss: 0.5427, train_acc: 0.8086\nEpoch [73], train_loss: 0.5737, train_acc: 0.8025\nEpoch [74], train_loss: 0.5454, train_acc: 0.8097\nEpoch [75], train_loss: 0.5277, train_acc: 0.8159\nEpoch [76], train_loss: 0.5339, train_acc: 0.8144\nEpoch [77], train_loss: 0.5319, train_acc: 0.8148\nEpoch [78], train_loss: 0.5340, train_acc: 0.8138\nEpoch [79], train_loss: 0.5322, train_acc: 0.8150\n\nTotal training time: 1612.98 seconds\n","output_type":"stream"}]}]}